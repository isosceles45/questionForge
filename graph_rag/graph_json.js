var graphJson = {"directed": false, "multigraph": false, "graph": {"node_default": {}, "edge_default": {}}, "nodes": [{"entity_type": "PERSON", "description": "Richard S. Sutton is an author associated with \'Reinforcement Learning: An Introduction,\' contributing foundational knowledge in the field.<SEP>Richard S. Sutton is an author of the book \'Reinforcement Learning: An Introduction,\' contributing significantly to the foundational understanding of reinforcement learning.<SEP>Richard S. Sutton is an author or researcher referenced for his work on Reinforcement Learning, specifically his book \'Reinforcement Learning: An Introduction.\'", "source_id": "chunk-740e20aa34b4c6dce6f61e7f610935f1<SEP>chunk-043dea27423dc3b2d7a7f7a4eee1c48d<SEP>chunk-4273b853b0d6a4d42c5e1c70d87ceb09", "clusters": "[{level: 0, cluster: 1}]", "id": "RICHARD S. SUTTON"}, {"entity_type": "PERSON", "description": "Andrew G. Barto is a co-author with Richard S. Sutton on a foundational book on Reinforcement Learning, which is referenced in the course.<SEP>Andrew G. Barto is an author of the book \'Reinforcement Learning: An Introduction,\' providing foundational knowledge on the subject.<SEP>Andrew G. Barto is an author associated with \'Reinforcement Learning: An Introduction,\' contributing foundational knowledge in the field.", "source_id": "chunk-740e20aa34b4c6dce6f61e7f610935f1<SEP>chunk-043dea27423dc3b2d7a7f7a4eee1c48d<SEP>chunk-4273b853b0d6a4d42c5e1c70d87ceb09", "clusters": "[{level: 0, cluster: 1}]", "id": "ANDREW G. BARTO"}, {"entity_type": "PERSON", "description": "Alessandro Palmas is an author of \'The Reinforcement Learning Workshop,\' focused on applying RL algorithms to control problems.<SEP>Alessandro Palmas is an author of \'The Reinforcement Learning Workshop,\' focusing on the application of cutting-edge reinforcement learning algorithms.<SEP>Alessandro Palmas is one of the authors of \'The Reinforcement Learning Workshop\' which is a resource referenced in the course.", "source_id": "chunk-740e20aa34b4c6dce6f61e7f610935f1<SEP>chunk-043dea27423dc3b2d7a7f7a4eee1c48d<SEP>chunk-4273b853b0d6a4d42c5e1c70d87ceb09", "clusters": "[{level: 0, cluster: 0}]", "id": "ALESSANDRO PALMAS"}, {"entity_type": "PERSON", "description": "Dr. Alexandra Galina Petre is a co-author of \'The Reinforcement Learning Workshop,\' and contributes to teaching practical applications of RL algorithms.<SEP>Dr. Alexandra Galina Petre is a co-author of \'The Reinforcement Learning Workshop,\' contributing to the understanding of applying reinforcement learning algorithms.<SEP>Dr. Alexandra Galina Petre is an author of \'The Reinforcement Learning Workshop,\' focused on applying RL algorithms to control problems.", "source_id": "chunk-740e20aa34b4c6dce6f61e7f610935f1<SEP>chunk-043dea27423dc3b2d7a7f7a4eee1c48d<SEP>chunk-4273b853b0d6a4d42c5e1c70d87ceb09", "clusters": "[{level: 0, cluster: 0}]", "id": "DR. ALEXANDRA GALINA PETRE"}, {"entity_type": "PERSON", "description": "Emanuele Ghelfi is a co-author of \'The Reinforcement Learning Workshop,\' focusing on control problem applications of reinforcement learning.<SEP>Emanuele Ghelfi is listed as a co-author of \'The Reinforcement Learning Workshop,\' a book providing insights into reinforcement learning applications.<SEP>Emanuele Ghelfi is an author of \'The Reinforcement Learning Workshop,\' focused on applying RL algorithms to control problems.", "source_id": "chunk-740e20aa34b4c6dce6f61e7f610935f1<SEP>chunk-043dea27423dc3b2d7a7f7a4eee1c48d<SEP>chunk-4273b853b0d6a4d42c5e1c70d87ceb09", "clusters": "[{level: 0, cluster: 0}]", "id": "EMANUELE GHELFI"}, {"entity_type": "PERSON", "description": "Phil Winder is an author of \'Reinforcement Learning Industrial Applications with Intelligent Agents,\' detailing modern industrial RL applications.<SEP>Phil Winder is an author of \'Reinforcement Learning Industrial Applications with Intelligent Agents,\' discussing industrial applications of RL.<SEP>Phil Winder is an author whose work \'Reinforcement Learning Industrial Applications with Intelligent Agents\' is referenced in the course.", "source_id": "chunk-740e20aa34b4c6dce6f61e7f610935f1<SEP>chunk-043dea27423dc3b2d7a7f7a4eee1c48d<SEP>chunk-4273b853b0d6a4d42c5e1c70d87ceb09", "clusters": "[{level: 0, cluster: 3}]", "id": "PHIL WINDER"}, {"entity_type": "PERSON", "description": "Dr Engr S M Farrukh Akhtar is an author of \'Practical Reinforcement Learning,\' providing insights into practical applications of reinforcement learning.<SEP>Dr Engr S M Farrukh Akhtar is an author of \'Practical Reinforcement Learning,\' which provides practical insights into reinforcement learning applications.<SEP>Dr Engr S M Farrukh Akhtar is an author of \'Practical Reinforcement Learning,\' providing practical insights into RL.", "source_id": "chunk-740e20aa34b4c6dce6f61e7f610935f1<SEP>chunk-043dea27423dc3b2d7a7f7a4eee1c48d<SEP>chunk-4273b853b0d6a4d42c5e1c70d87ceb09", "clusters": "[{level: 0, cluster: 2}]", "id": "DR ENGR S M FARRUKH AKHTAR"}, {"entity_type": "EVENT", "description": "Reinforcement Learning (ADDO8013) is a course designed to provide a comprehensive understanding of foundational and advanced topics in reinforcement learning.<SEP>The course covers aspects of Reinforcement Learning, including algorithms and applications, aiming to provide a comprehensive understanding of its concepts and implementations.", "source_id": "chunk-043dea27423dc3b2d7a7f7a4eee1c48d<SEP>chunk-4273b853b0d6a4d42c5e1c70d87ceb09", "id": "REINFORCEMENT LEARNING COURSE"}, {"entity_type": "ORGANIZATION", "description": "Packt Publishing is a publishing company referenced for two books on reinforcement learning, authored by Dr. Alexandra Galina Petre and Dr. Engr S M Farrukh Akhtar.", "source_id": "chunk-4273b853b0d6a4d42c5e1c70d87ceb09", "clusters": "[{level: 0, cluster: 2}]", "id": "PACKT PUBLISHING"}, {"entity_type": "ORGANIZATION", "description": "O\'Reilly is a publishing company associated with the book \'Reinforcement Learning Industrial Applications with Intelligent Agents\' by Phil Winder.", "source_id": "chunk-4273b853b0d6a4d42c5e1c70d87ceb09", "clusters": "[{level: 0, cluster: 3}]", "id": "O\'REILLY"}, {"entity_type": "EVENT", "description": "A type of machine learning that is concerned with how agents should take actions in an environment to maximize cumulative reward.<SEP>Reinforcement Learning is a type of machine learning focused on making sequences of decisions by rewarding desired behaviors.<SEP>Reinforcement Learning is the subject of the exam, focusing on the iterative process to train algorithms to make sequences of decisions by learning from the environment.<SEP>Reinforcement Learning is the subject of the exam, focusing on different aspects like algorithms, applications, and theoretical concepts in AI.", "source_id": "chunk-b5cff8b84dd85a3cd6bfa31344333899<SEP>chunk-4273b853b0d6a4d42c5e1c70d87ceb09<SEP>chunk-9a034c9a3ca1a357398b4da70748efa8<SEP>chunk-043dea27423dc3b2d7a7f7a4eee1c48d", "clusters": "[{level: 0, cluster: 0}]", "id": "REINFORCEMENT LEARNING"}, {"entity_type": "CONCEPT", "description": "A model-free reinforcement learning algorithm used to find the optimal action-selection policy using a Q-function to approximate value.<SEP>Q-Learning is an important machine learning algorithm used in reinforcement learning for learning the value of actions in various states.<SEP>Q-learning is an off-policy method in reinforcement learning that aims to find the best action to take given the current state.<SEP>Q-learning is a model-free reinforcement learning algorithm used to find the optimal action-selection policy.<SEP>Q-learning is an off-policy reinforcement learning algorithm that updates its Q-values using the maximum reward possible for the next state, regardless of the actual actions taken.<SEP>Q-Learning is a Reinforcement Learning algorithm covered in the course, focusing on learning the value of actions.<SEP>Q-learning is an off-policy method in Reinforcement Learning that seeks to learn the optimal policy independently of the agent\'s actions by using a greedy policy for updates.", "source_id": "chunk-043dea27423dc3b2d7a7f7a4eee1c48d<SEP>chunk-4273b853b0d6a4d42c5e1c70d87ceb09<SEP>chunk-b5cff8b84dd85a3cd6bfa31344333899<SEP>chunk-0d989122d8c7d74335a0147cfedc9167<SEP>chunk-9a034c9a3ca1a357398b4da70748efa8<SEP>chunk-a0fab03582fdc8423aa2227d4c93c043<SEP>chunk-740e20aa34b4c6dce6f61e7f610935f1", "clusters": "[{level: 0, cluster: 1}]", "id": "Q-LEARNING"}, {"entity_type": "CONCEPT", "description": "SARSA is an on-policy method in Reinforcement Learning that updates policies based on the actions actually taken by following the current policy while learning.<SEP>SARSA is an on-policy method used in reinforcement learning to update policy based on action-value functions.<SEP>SARSA, which stands for State-Action-Reward-State-Action, is an algorithm in reinforcement learning used to calculate the optimal policy.<SEP>SARSA is an on-policy reinforcement learning algorithm that updates its Q-values based on the current policy and the actions actually taken.<SEP>SARSA is an on-policy reinforcement learning algorithm that updates the action-value function based on the action actually taken.<SEP>SARSA, or State Action Reward State Action, is a Reinforcement Learning algorithm introduced in the course, used to model decision-making processes.", "source_id": "chunk-4273b853b0d6a4d42c5e1c70d87ceb09<SEP>chunk-b5cff8b84dd85a3cd6bfa31344333899<SEP>chunk-0d989122d8c7d74335a0147cfedc9167<SEP>chunk-9a034c9a3ca1a357398b4da70748efa8<SEP>chunk-a0fab03582fdc8423aa2227d4c93c043<SEP>chunk-740e20aa34b4c6dce6f61e7f610935f1", "clusters": "[{level: 0, cluster: 1}]", "id": "SARSA"}, {"entity_type": "CONCEPT", "description": "A problem in reinforcement learning used to describe a situation where a decision-maker must choose between multiple options to maximize rewards.<SEP>The n-Armed Bandit Problem is a reinforcement learning problem that involves decision making to maximize return.<SEP>The n-Armed Bandit Problem is a foundational concept in RL dealing with action-value methods and decision-making under uncertainty.", "source_id": "chunk-740e20aa34b4c6dce6f61e7f610935f1<SEP>chunk-043dea27423dc3b2d7a7f7a4eee1c48d<SEP>chunk-4273b853b0d6a4d42c5e1c70d87ceb09", "id": "N-ARMED BANDIT PROBLEM"}, {"entity_type": "CONCEPT", "description": "Markov Decision Processes are mathematical frameworks used in RL to model decision-making situations where outcomes are partly random and partly under the control of a decision maker.<SEP>Markov Decision Processes are mathematical models used for decision-making in environments where outcomes are partly random and partly under control of a decision maker.", "source_id": "chunk-740e20aa34b4c6dce6f61e7f610935f1<SEP>chunk-4273b853b0d6a4d42c5e1c70d87ceb09", "id": "MARKOV DECISION PROCESSES"}, {"entity_type": "CONCEPT", "description": "A method for solving complex problems by breaking them down into simpler subproblems, widely used in reinforcement learning for policy optimization.<SEP>Dynamic Programming is a method used in reinforcement learning to solve problems by breaking them down into simpler subproblems.<SEP>Dynamic Programming in RL involves a set of algorithms including Policy Iteration and Value Iteration for solving complex decision-making problems.", "source_id": "chunk-740e20aa34b4c6dce6f61e7f610935f1<SEP>chunk-043dea27423dc3b2d7a7f7a4eee1c48d<SEP>chunk-4273b853b0d6a4d42c5e1c70d87ceb09", "id": "DYNAMIC PROGRAMMING"}, {"entity_type": "TECHNOLOGY", "description": "A class of algorithms that rely on repeated random sampling to obtain numerical results, used in reinforcement learning to estimate the value of actions.<SEP>Monte Carlo Methods are used in reinforcement learning for prediction and control by averaging sample returns.<SEP>Monte Carlo Methods in RL involve prediction and control techniques using random sampling to understand decision-making situations.", "source_id": "chunk-740e20aa34b4c6dce6f61e7f610935f1<SEP>chunk-043dea27423dc3b2d7a7f7a4eee1c48d<SEP>chunk-4273b853b0d6a4d42c5e1c70d87ceb09", "id": "MONTE CARLO METHODS"}, {"entity_type": "TECHNOLOGY", "description": "A combination of Monte Carlo ideas and dynamic programming ideas whose aim is to learn directly from raw experience without a model of the environment\'s dynamics.<SEP>Temporal-Difference Learning is a reinforcement learning approach that updates value estimates based in part on estimates of future values.<SEP>Temporal-Difference Learning is a class of RL methods focusing on learning prediction and control policies based on temporal differences.", "source_id": "chunk-740e20aa34b4c6dce6f61e7f610935f1<SEP>chunk-043dea27423dc3b2d7a7f7a4eee1c48d<SEP>chunk-4273b853b0d6a4d42c5e1c70d87ceb09", "id": "TEMPORAL-DIFFERENCE LEARNING"}, {"entity_type": "APPLICATION", "description": "A real-world problem where reinforcement learning can be applied to optimize the timing and sequence of elevator calls.<SEP>Elevator Dispatching is a real-world application case study of reinforcement learning to optimize the operation of elevators.<SEP>Elevator Dispatching is a real-world application of RL covered in the course, illustrating practical use cases of RL techniques.", "source_id": "chunk-740e20aa34b4c6dce6f61e7f610935f1<SEP>chunk-043dea27423dc3b2d7a7f7a4eee1c48d<SEP>chunk-4273b853b0d6a4d42c5e1c70d87ceb09", "id": "ELEVATOR DISPATCHING"}, {"entity_type": "CONCEPT", "description": "A problem where reinforcement learning algorithms can be used to efficiently allocate communication channels to maximize performance in networks.<SEP>Dynamic Channel Allocation is an application of reinforcement learning discussed in the course to manage channel allocation in communication networks.<SEP>Dynamic Channel Allocation refers to a reinforcement learning algorithm designed to optimize channel allocation in wireless networks.<SEP>Dynamic Channel Allocation is another real-world application of RL discussed in the course, showing how RL can optimize resource distribution.<SEP>Dynamic Channel Allocation is a method to efficiently manage the allocation of channels in a wireless communication network using Reinforcement Learning techniques.", "source_id": "chunk-043dea27423dc3b2d7a7f7a4eee1c48d<SEP>chunk-4273b853b0d6a4d42c5e1c70d87ceb09<SEP>chunk-0d989122d8c7d74335a0147cfedc9167<SEP>chunk-9a034c9a3ca1a357398b4da70748efa8<SEP>chunk-740e20aa34b4c6dce6f61e7f610935f1", "id": "DYNAMIC CHANNEL ALLOCATION"}, {"entity_type": "APPLICATION", "description": "A complex scheduling problem in manufacturing that can be optimized using reinforcement learning techniques.<SEP>Job-Shop Scheduling is a case study in reinforcement learning used to optimize scheduling in manufacturing processes.<SEP>Job-Shop Scheduling is covered as an application of RL, demonstrating the optimization of job assignments to resources over time.", "source_id": "chunk-740e20aa34b4c6dce6f61e7f610935f1<SEP>chunk-043dea27423dc3b2d7a7f7a4eee1c48d<SEP>chunk-4273b853b0d6a4d42c5e1c70d87ceb09", "id": "JOB-SHOP SCHEDULING"}, {"entity_type": "EVENT", "description": "The year 2024 is when the exam is scheduled to take place.", "source_id": "chunk-9a034c9a3ca1a357398b4da70748efa8", "id": "2024"}, {"entity_type": "EVENT", "description": "The semester VIII indicates the academic term for which this exam is relevant.", "source_id": "chunk-9a034c9a3ca1a357398b4da70748efa8", "id": "VIII"}, {"entity_type": "CONCEPT", "description": "The Policy Improvement Theorem in reinforcement learning provides a foundation for policy iteration, ensuring that policy enhancements lead to improved value functions.<SEP>The Policy Improvement Theorem is a fundamental principle in reinforcement learning that describes how policies can be iteratively improved to achieve better rewards.<SEP>The Policy Improvement Theorem is a fundamental principle in Reinforcement Learning that assures that policy iteration will improve or maintain policy performance.", "source_id": "chunk-b5cff8b84dd85a3cd6bfa31344333899<SEP>chunk-0d989122d8c7d74335a0147cfedc9167<SEP>chunk-9a034c9a3ca1a357398b4da70748efa8", "id": "POLICY IMPROVEMENT THEOREM"}, {"entity_type": "EVENT", "description": "Markov Decision Processes are mathematical frameworks used in reinforcement learning to model decision-making tasks with Markov properties.", "source_id": "chunk-9a034c9a3ca1a357398b4da70748efa8", "id": "MARKOV DECISION PROCESSES (MDPS)"}, {"entity_type": "CONCEPT", "description": "The UCB Action Selection method is used within multi-armed bandit problems to balance exploration and exploitation by determining the next action based on calculated confidence bounds.<SEP>UCB Action Selection is a strategy in multi-armed bandit problems to select actions based on the upper confidence bounds of rewards.<SEP>UCB Action Selection is an algorithm used in the multi-armed bandit problem which balances exploration and exploitation by considering the uncertainty of action-value estimates.", "source_id": "chunk-b5cff8b84dd85a3cd6bfa31344333899<SEP>chunk-0d989122d8c7d74335a0147cfedc9167<SEP>chunk-9a034c9a3ca1a357398b4da70748efa8", "id": "UPPER-CONFIDENCE-BOUND (UCB) ACTION SELECTION"}, {"entity_type": "CONCEPT", "description": "The k-armed bandit problem explores the trade-off between exploration and exploitation in decision-making, particularly in optimizing processes.<SEP>The k-armed bandit problem is a classical problem in Reinforcement Learning focused on optimizing the selection between different options (arms) to maximize rewards over time while balancing exploration and exploitation trade-offs.", "source_id": "chunk-0d989122d8c7d74335a0147cfedc9167<SEP>chunk-9a034c9a3ca1a357398b4da70748efa8", "id": "K-ARMED BANDIT PROBLEM"}, {"entity_type": "CONCEPT", "description": "A method to estimate the value of states or state-action pairs using observed returns following each visit to a state or pair.<SEP>Monte Carlo Prediction is a method in reinforcement learning for evaluating the expected return of a state by using random sampling.<SEP>Monte Carlo Prediction is a method in Reinforcement Learning used to estimate the value of states by averaging the returns received following visits to those states.", "source_id": "chunk-043dea27423dc3b2d7a7f7a4eee1c48d<SEP>chunk-0d989122d8c7d74335a0147cfedc9167<SEP>chunk-9a034c9a3ca1a357398b4da70748efa8", "id": "MONTE CARLO PREDICTION"}, {"entity_type": "EVENT", "description": "These are fundamental concepts in reinforcement learning that describe the objectives, outcomes, sequences, and mechanisms for decision-making and action consequences.", "source_id": "chunk-9a034c9a3ca1a357398b4da70748efa8", "id": "GOALS, REWARDS, RETURNS, EPISODES, AND DISCOUNTING"}, {"entity_type": "EVENT", "description": "A foundational textbook on reinforcement learning concepts and algorithms, authored by Richard S. Sutton and Andrew G. Barto.", "source_id": "chunk-043dea27423dc3b2d7a7f7a4eee1c48d", "id": "REINFORCEMENT LEARNING: AN INTRODUCTION"}, {"entity_type": "EVENT", "description": "A workshop-focused book by Alessandro Palmas, Dr. Alexandra Galina Petre, and Emanuele Ghelfi that teaches application of RL algorithms.", "source_id": "chunk-043dea27423dc3b2d7a7f7a4eee1c48d", "id": "THE REINFORCEMENT LEARNING WORKSHOP"}, {"entity_type": "EVENT", "description": "A book by Dr Engr S M Farrukh Akhtar that provides practical insights and applications of reinforcement learning algorithms.", "source_id": "chunk-043dea27423dc3b2d7a7f7a4eee1c48d", "id": "PRACTICAL REINFORCEMENT LEARNING"}, {"entity_type": "EVENT", "description": "A book by Phil Winder that highlights the use of RL in industrial settings with intelligent agents.", "source_id": "chunk-043dea27423dc3b2d7a7f7a4eee1c48d", "id": "REINFORCEMENT LEARNING INDUSTRIAL APPLICATIONS WITH INTELLIGENT AGENTS"}, {"entity_type": "CONCEPT", "description": "An on-policy reinforcement learning algorithm that updates the action-value function based on the action taken and the state observed from the environment.", "source_id": "chunk-043dea27423dc3b2d7a7f7a4eee1c48d", "id": "STATE ACTION REWARD STATE ACTION (SARSA)"}, {"entity_type": "CONCEPT", "description": "A mathematical framework used for modeling decision making in situations where outcomes are partly random and partly controlled by the decision maker.<SEP>Markov Decision Process is a mathematical framework used in reinforcement learning for modeling decision-making processes.<SEP>An MDP is a mathematical framework in Reinforcement Learning used to model decision-making in situations with outcomes that are partly random and partly under the control of a decision-maker.", "source_id": "chunk-b5cff8b84dd85a3cd6bfa31344333899<SEP>chunk-0d989122d8c7d74335a0147cfedc9167<SEP>chunk-043dea27423dc3b2d7a7f7a4eee1c48d", "clusters": "[{level: 0, cluster: 0}]", "id": "MARKOV DECISION PROCESS (MDP)"}, {"entity_type": "CONCEPT", "description": "The point at which an agent perceives its environment and can perform actions to affect it, crucial in reinforcement learning.", "source_id": "chunk-043dea27423dc3b2d7a7f7a4eee1c48d", "id": "AGENT\u2013ENVIRONMENT INTERFACE"}, {"entity_type": "CONCEPT", "description": "A process in dynamic programming and reinforcement learning to compute the value of a policy, determining how good it is.", "source_id": "chunk-043dea27423dc3b2d7a7f7a4eee1c48d", "id": "POLICY EVALUATION"}, {"entity_type": "CONCEPT", "description": "A method in dynamic programming that involves policy evaluation and policy improvement until an optimal policy is found.", "source_id": "chunk-043dea27423dc3b2d7a7f7a4eee1c48d", "id": "POLICY ITERATION"}, {"entity_type": "CONCEPT", "description": "An algorithm to compute the optimal policy by iteratively improving the value functions.", "source_id": "chunk-043dea27423dc3b2d7a7f7a4eee1c48d", "id": "VALUE ITERATION"}, {"entity_type": "CONCEPT", "description": "A framework combining policy evaluation and improvement steps, designed to iteratively find an optimal policy.", "source_id": "chunk-043dea27423dc3b2d7a7f7a4eee1c48d", "id": "GENERALIZED POLICY ITERATION"}, {"entity_type": "CONCEPT", "description": "A method used in reinforcement learning to estimate the state\'s value function using temporal differences.", "source_id": "chunk-043dea27423dc3b2d7a7f7a4eee1c48d", "id": "TD PREDICTION"}, {"entity_type": "CONCEPT", "description": "A method in reinforcement learning to learn the optimal policy using techniques like Q-Learning.", "source_id": "chunk-043dea27423dc3b2d7a7f7a4eee1c48d", "id": "TD CONTROL"}, {"entity_type": "EVENT", "description": "A publication focusing on the use of reinforcement learning in industrial applications, authored by Phil Winder.", "source_id": "chunk-043dea27423dc3b2d7a7f7a4eee1c48d", "id": "PHIL WINDER\'S BOOK"}, {"entity_type": "ORGANIZATION", "description": "A publishing company that has released multiple books on reinforcement learning applications.", "source_id": "chunk-043dea27423dc3b2d7a7f7a4eee1c48d", "id": "PACT PUBLISHING"}, {"entity_type": "ORGANIZATION", "description": "A technology and business media company that published works focused on reinforcement learning applications.", "source_id": "chunk-043dea27423dc3b2d7a7f7a4eee1c48d", "id": "O\u2019REILLY"}, {"entity_type": "CONCEPT", "description": "Multi-Armed Bandit Problems involve decision-making strategies to maximize rewards over time, relevant to reinforcement learning.", "source_id": "chunk-b5cff8b84dd85a3cd6bfa31344333899", "clusters": "[{level: 0, cluster: 0}]", "id": "MULTI-ARMED BANDIT PROBLEMS"}, {"entity_type": "EVENT", "description": "Semester VIII refers to the final term of an academic year, often involving advanced coursework and evaluations.", "source_id": "chunk-b5cff8b84dd85a3cd6bfa31344333899", "id": "SEMESTER VIII"}, {"entity_type": "GEO", "description": "Washington is a location mentioned as part of communications, representing a point of contact or decision-making process.", "source_id": "chunk-b5cff8b84dd85a3cd6bfa31344333899", "id": "WASHINGTON"}, {"entity_type": "CONCEPT", "description": "Gradient Bandit Algorithms are a type of reinforcement learning algorithm that uses preferences and softmax action selection to optimize decisions.", "source_id": "chunk-b5cff8b84dd85a3cd6bfa31344333899", "id": "GRADIENT BANDIT ALGORITHMS"}, {"entity_type": "CONCEPT", "description": "Optimistic Initial Values in reinforcement learning are used to encourage exploration by initially assuming higher potential rewards from actions.", "source_id": "chunk-b5cff8b84dd85a3cd6bfa31344333899", "id": "OPTIMISTIC INITIAL VALUES"}, {"entity_type": "CONCEPT", "description": "The Discount Factor in reinforcement learning determines the present value of future rewards and influences the agent\'s decision-making process.", "source_id": "chunk-b5cff8b84dd85a3cd6bfa31344333899", "id": "DISCOUNT FACTOR"}, {"entity_type": "CONCEPT", "description": "The Exploration-Exploitation Trade-off involves balancing the choice between exploring new actions to find more rewarding ones and exploiting known actions with expected high rewards.", "source_id": "chunk-b5cff8b84dd85a3cd6bfa31344333899", "id": "EXPLORATION-EXPLOITATION TRADE-OFF"}, {"entity_type": "GEO", "description": "Office Environment is a location scenario used in reinforcement learning, particularly involving a task for a mobile robot during the application of reinforcement learning strategies.", "source_id": "chunk-b5cff8b84dd85a3cd6bfa31344333899", "id": "OFFICE ENVIRONMENT"}, {"entity_type": "CONCEPT", "description": "The Mobile Robot Task refers to the application of reinforcement learning principles to enhance a robot\'s performance in tasks like collecting soda cans in an office environment.", "source_id": "chunk-b5cff8b84dd85a3cd6bfa31344333899", "id": "MOBILE ROBOT TASK"}, {"entity_type": "CONCEPT", "description": "The Agent\'s Decision-Making Process in reinforcement learning involves selecting actions based on policy and learned value functions, affected by factors like the discount factor.", "source_id": "chunk-b5cff8b84dd85a3cd6bfa31344333899", "id": "AGENT\'S DECISION-MAKING PROCESS"}, {"entity_type": "CONCEPT", "description": "Theorem Proofs in RL refer to the formal demonstrations of the validity of theorems, such as the Policy Improvement Theorem, within Reinforcement Learning.", "source_id": "chunk-b5cff8b84dd85a3cd6bfa31344333899", "id": "THEOREM PROOFS IN RL"}, {"entity_type": "CONCEPT", "description": "Action Selection Methods in reinforcement learning determine which actions to take, including techniques like UCB and softmax in bandit algorithms.", "source_id": "chunk-b5cff8b84dd85a3cd6bfa31344333899", "id": "ACTION SELECTION METHODS"}, {"entity_type": "CONCEPT", "description": "Rewards in a Markov Decision Process are the feedback received by the agent after taking actions, guiding the learning and decision-making.", "source_id": "chunk-b5cff8b84dd85a3cd6bfa31344333899", "id": "REWARDS IN MDP"}, {"entity_type": "CONCEPT", "description": "Episodes in reinforcement learning are sequences of states, actions, and rewards, ending with a terminal state, used to evaluate agent performance.", "source_id": "chunk-b5cff8b84dd85a3cd6bfa31344333899", "id": "EPISODES IN RL"}, {"entity_type": "CONCEPT", "description": "Returns refer to the total accumulated reward in reinforcement learning, often considered as a measure of policy success over an episode or time horizon.", "source_id": "chunk-b5cff8b84dd85a3cd6bfa31344333899", "id": "RETURNS IN RL"}, {"entity_type": "CONCEPT", "description": "In reinforcement learning, an algorithm\'s performance and convergence pertain to how well and quickly it learns an optimal policy.", "source_id": "chunk-b5cff8b84dd85a3cd6bfa31344333899", "id": "ALGORITHM\'S PERFORMANCE AND CONVERGENCE"}, {"entity_type": "CONCEPT", "description": "Reinforcement Learning Algorithms refer to a class of algorithms in machine learning dedicated to making optimal decisions based on immediate feedback, such as SARSA and Q-learning.", "source_id": "chunk-a0fab03582fdc8423aa2227d4c93c043", "clusters": "[{level: 0, cluster: 1}]", "id": "REINFORCEMENT LEARNING ALGORITHMS"}, {"entity_type": "CONCEPT", "description": "Policy Improvement refers to methods or strategies aimed at enhancing policies within the context of reinforcement learning.", "source_id": "chunk-a0fab03582fdc8423aa2227d4c93c043", "id": "POLICY IMPROVEMENT"}, {"entity_type": "CONCEPT", "description": "Theorems in this context refer to established principles or propositions in reinforcement learning that have been proven through formal methods.", "source_id": "chunk-a0fab03582fdc8423aa2227d4c93c043", "id": "THEOREMS"}, {"entity_type": "CONCEPT", "description": "Proofs involve logical argumentation and evidence used to establish the validity of theorems in reinforcement learning.", "source_id": "chunk-a0fab03582fdc8423aa2227d4c93c043", "id": "PROOFS"}, {"entity_type": "EVENT", "description": "The End Semester Examination is an assessment event where students are tested on their knowledge and understanding of topics covered during the semester, such as reinforcement learning.", "source_id": "chunk-a0fab03582fdc8423aa2227d4c93c043", "id": "END SEMESTER EXAMINATION"}, {"entity_type": "CONCEPT", "description": "Cognitive Level: Analysis refers to the level of thinking skills required, focusing on breaking down complex material into component parts and understanding its structure.", "source_id": "chunk-a0fab03582fdc8423aa2227d4c93c043", "id": "COGNITIVE LEVEL: ANALYSIS"}, {"entity_type": "CONCEPT", "description": "Cognitive Level: Comparison refers to evaluating by identifying similarities and differences between subjects, such as comparing SARSA and Q-learning.", "source_id": "chunk-a0fab03582fdc8423aa2227d4c93c043", "id": "COGNITIVE LEVEL: COMPARISON"}, {"entity_type": "CONCEPT", "description": "Question Type: Long Answer refers to a type of question in exams that requires detailed and comprehensive responses.", "source_id": "chunk-a0fab03582fdc8423aa2227d4c93c043", "id": "QUESTION TYPE: LONG ANSWER"}, {"entity_type": "EVENT", "description": "Reinforcement Learning (ADDO8013) is a course covering foundational concepts and algorithms in Reinforcement Learning, preparing students for real-world application.", "source_id": "chunk-740e20aa34b4c6dce6f61e7f610935f1", "clusters": "[{level: 0, cluster: 1}]", "id": "REINFORCEMENT LEARNING (ADDO8013)"}, {"entity_type": "EVENT", "description": "The Reinforcement Learning Exam is an academic evaluation set in the year 2024, focused on testing students on various advanced concepts within Reinforcement Learning over a duration of two hours for a total of 60 marks.", "source_id": "chunk-0d989122d8c7d74335a0147cfedc9167", "id": "REINFORCEMENT LEARNING EXAM 2024"}, {"entity_type": "CONCEPT", "description": "Model-based Reinforcement Learning involves building a model of the environment, using it to simulate decision-making processes and improve policy.", "source_id": "chunk-0d989122d8c7d74335a0147cfedc9167", "id": "MODEL-BASED REINFORCEMENT LEARNING"}, {"entity_type": "CONCEPT", "description": "Model-free Reinforcement Learning directly learns the value of actions or states without an explicit model of the environment.", "source_id": "chunk-0d989122d8c7d74335a0147cfedc9167", "id": "MODEL-FREE REINFORCEMENT LEARNING"}, {"entity_type": "CONCEPT", "description": "Policy and Value Iteration are methods used in Reinforcement Learning to solve MDPs by iteratively evaluating and improving policies until they converge to the optimal policy.", "source_id": "chunk-0d989122d8c7d74335a0147cfedc9167", "id": "POLICY AND VALUE ITERATION"}, {"entity_type": "CONCEPT", "description": "Temporal Difference Learning is an approach in Reinforcement Learning that combines ideas from Monte Carlo methods and dynamic programming, focusing on learning directly from raw experiences without a model of the environment.", "source_id": "chunk-0d989122d8c7d74335a0147cfedc9167", "id": "TEMPORAL DIFFERENCE LEARNING"}, {"entity_type": "CONCEPT", "description": "Exploration-Exploitation Trade-offs refer to the dilemma in Reinforcement Learning between exploring new actions to discover their effects and exploiting known actions that yield high rewards.", "source_id": "chunk-0d989122d8c7d74335a0147cfedc9167", "id": "EXPLORATION-EXPLOITATION TRADE-OFFS"}, {"entity_type": "CONCEPT", "description": "Cognitive Level in the context of this exam refers to the level of cognitive processing required to answer the questions, indicating complexity and depth of understanding.", "source_id": "chunk-0d989122d8c7d74335a0147cfedc9167", "id": "COGNITIVE LEVEL"}, {"entity_type": "CONCEPT", "description": "Question Type describes the nature of the questions in the exam, in this case, they are long answer questions.", "source_id": "chunk-0d989122d8c7d74335a0147cfedc9167", "id": "QUESTION TYPE"}], "links": [{"weight": 9.0, "description": "Both are co-authors of the book \'Reinforcement Learning: An Introduction,\' which is a key reference for the course.", "source_id": "chunk-4273b853b0d6a4d42c5e1c70d87ceb09", "order": 1, "source": "RICHARD S. SUTTON", "target": "ANDREW G. BARTO"}, {"weight": 9.0, "description": "Richard S. Sutton\'s work is a key reference for the Reinforcement Learning course, providing foundational knowledge.", "source_id": "chunk-740e20aa34b4c6dce6f61e7f610935f1", "order": 1, "source": "RICHARD S. SUTTON", "target": "REINFORCEMENT LEARNING (ADDO8013)"}, {"weight": 9.0, "description": "Andrew G. Barto\'s work is a key reference for the Reinforcement Learning course, providing foundational knowledge.", "source_id": "chunk-740e20aa34b4c6dce6f61e7f610935f1", "order": 1, "source": "ANDREW G. BARTO", "target": "REINFORCEMENT LEARNING (ADDO8013)"}, {"weight": 8.0, "description": "Co-authors of \'The Reinforcement Learning Workshop,\' contributing to the course\'s reading materials on reinforcement learning.", "source_id": "chunk-4273b853b0d6a4d42c5e1c70d87ceb09", "order": 1, "source": "ALESSANDRO PALMAS", "target": "DR. ALEXANDRA GALINA PETRE"}, {"weight": 8.0, "description": "Alessandro Palmas\'s work offers practical RL applications, enhancing the course\'s practical focus.", "source_id": "chunk-740e20aa34b4c6dce6f61e7f610935f1", "order": 1, "source": "ALESSANDRO PALMAS", "target": "REINFORCEMENT LEARNING (ADDO8013)"}, {"weight": 8.0, "description": "Co-authors of \'The Reinforcement Learning Workshop,\' providing collaborative insights on cutting-edge reinforcement learning algorithms.", "source_id": "chunk-4273b853b0d6a4d42c5e1c70d87ceb09", "order": 1, "source": "DR. ALEXANDRA GALINA PETRE", "target": "EMANUELE GHELFI"}, {"weight": 7.0, "description": "Packt Publishing is listed as the publisher for \'The Reinforcement Learning Workshop,\' co-authored by Dr. Alexandra Galina Petre.", "source_id": "chunk-4273b853b0d6a4d42c5e1c70d87ceb09", "order": 1, "source": "DR. ALEXANDRA GALINA PETRE", "target": "PACKT PUBLISHING"}, {"weight": 8.0, "description": "Dr. Alexandra Galina Petre\'s work provides practical applications in RL, aligning with the course\'s application goals.", "source_id": "chunk-740e20aa34b4c6dce6f61e7f610935f1", "order": 1, "source": "DR. ALEXANDRA GALINA PETRE", "target": "REINFORCEMENT LEARNING (ADDO8013)"}, {"weight": 8.0, "description": "Emanuele Ghelfi\'s contribution to practical RL applications is integrated into the course\'s content.", "source_id": "chunk-740e20aa34b4c6dce6f61e7f610935f1", "order": 1, "source": "EMANUELE GHELFI", "target": "REINFORCEMENT LEARNING (ADDO8013)"}, {"weight": 7.0, "description": "O\'Reilly is the publisher of \'Reinforcement Learning Industrial Applications with Intelligent Agents,\' written by Phil Winder.", "source_id": "chunk-4273b853b0d6a4d42c5e1c70d87ceb09", "order": 1, "source": "PHIL WINDER", "target": "O\'REILLY"}, {"weight": 8.0, "description": "Phil Winder\'s insights into industrial RL applications contribute to the course\'s relevance in industrial contexts.", "source_id": "chunk-740e20aa34b4c6dce6f61e7f610935f1", "order": 1, "source": "PHIL WINDER", "target": "REINFORCEMENT LEARNING (ADDO8013)"}, {"weight": 7.0, "description": "Packt Publishing is the publisher of \'Practical Reinforcement Learning,\' authored by Dr Engr S M Farrukh Akhtar.", "source_id": "chunk-4273b853b0d6a4d42c5e1c70d87ceb09", "order": 1, "source": "DR ENGR S M FARRUKH AKHTAR", "target": "PACKT PUBLISHING"}, {"weight": 8.0, "description": "Dr Engr S M Farrukh Akhtar\'s work in practical RL provides significant applied learning for the course.", "source_id": "chunk-740e20aa34b4c6dce6f61e7f610935f1", "order": 1, "source": "DR ENGR S M FARRUKH AKHTAR", "target": "REINFORCEMENT LEARNING (ADDO8013)"}, {"weight": 17.0, "description": "SARSA is a method within the subject area of Reinforcement Learning, focusing on policy iteration.<SEP>SARSA is another key algorithm covered in the Reinforcement Learning curriculum for understanding on-policy learning.", "source_id": "chunk-b5cff8b84dd85a3cd6bfa31344333899<SEP>chunk-9a034c9a3ca1a357398b4da70748efa8", "order": 1, "source": "REINFORCEMENT LEARNING", "target": "SARSA"}, {"weight": 17.0, "description": "Q-learning is a significant algorithm taught within the curriculum of the Reinforcement Learning course.<SEP>Q-learning is another method within Reinforcement Learning, providing a perspective on the exploration-exploitation trade-off.", "source_id": "chunk-b5cff8b84dd85a3cd6bfa31344333899<SEP>chunk-9a034c9a3ca1a357398b4da70748efa8", "order": 1, "source": "REINFORCEMENT LEARNING", "target": "Q-LEARNING"}, {"weight": 9.0, "description": "An MDP is a key element in Reinforcement Learning for modeling environments and learning policies.", "source_id": "chunk-b5cff8b84dd85a3cd6bfa31344333899", "order": 1, "source": "REINFORCEMENT LEARNING", "target": "MARKOV DECISION PROCESS (MDP)"}, {"weight": 8.0, "description": "Multi-Armed Bandit Problems form the basis for understanding exploration and exploitation trade-offs in Reinforcement Learning.", "source_id": "chunk-b5cff8b84dd85a3cd6bfa31344333899", "order": 1, "source": "REINFORCEMENT LEARNING", "target": "MULTI-ARMED BANDIT PROBLEMS"}, {"weight": 9.0, "description": "The exam is entirely based on the subject matter of Reinforcement Learning, focusing on different subtopics and concepts within this domain.", "source_id": "chunk-0d989122d8c7d74335a0147cfedc9167", "order": 1, "source": "REINFORCEMENT LEARNING", "target": "REINFORCEMENT LEARNING EXAM 2024"}, {"weight": 23.0, "description": "Both Q-learning and SARSA are reinforcement learning algorithms used to update policies, but differ in terms of on-policy and off-policy approaches.<SEP>SARSA and Q-learning are compared in terms of being on-policy and off-policy methods in reinforcement learning.<SEP>Both SARSA and Q-learning are reinforcement learning methods, with key differences in how they update policies, SARSA being on-policy and Q-learning being off-policy.", "source_id": "chunk-a0fab03582fdc8423aa2227d4c93c043<SEP>chunk-b5cff8b84dd85a3cd6bfa31344333899<SEP>chunk-0d989122d8c7d74335a0147cfedc9167", "order": 1, "source": "Q-LEARNING", "target": "SARSA"}, {"weight": 8.0, "description": "Q-learning is a type of reinforcement learning algorithm used for off-policy learning, distinguishing itself from SARSA.", "source_id": "chunk-a0fab03582fdc8423aa2227d4c93c043", "order": 1, "source": "Q-LEARNING", "target": "REINFORCEMENT LEARNING ALGORITHMS"}, {"weight": 8.0, "description": "SARSA is one of the algorithms considered under the umbrella of reinforcement learning algorithms, focusing on on-policy learning.", "source_id": "chunk-a0fab03582fdc8423aa2227d4c93c043", "order": 1, "source": "SARSA", "target": "REINFORCEMENT LEARNING ALGORITHMS"}, {"weight": 6.0, "description": "Dynamic Channel Allocation using Reinforcement Learning is a topic of exploration and challenge, featured as part of the exam questions on advanced RL applications.", "source_id": "chunk-0d989122d8c7d74335a0147cfedc9167", "order": 1, "source": "DYNAMIC CHANNEL ALLOCATION", "target": "REINFORCEMENT LEARNING EXAM 2024"}, {"weight": 7.0, "description": "Semester VIII is scheduled to occur in the year 2024, indicating the timing of the academic term.", "source_id": "chunk-9a034c9a3ca1a357398b4da70748efa8", "order": 1, "source": "2024", "target": "VIII"}, {"weight": 8.0, "description": "The Policy Improvement Theorem is crucial for validating the processes of Policy and Value Iteration in Reinforcement Learning.", "source_id": "chunk-0d989122d8c7d74335a0147cfedc9167", "order": 1, "source": "POLICY IMPROVEMENT THEOREM", "target": "POLICY AND VALUE ITERATION"}, {"weight": 9.0, "description": "The k-armed bandit problem is often addressed using methods like UCB Action Selection to balance exploration and exploitation.", "source_id": "chunk-0d989122d8c7d74335a0147cfedc9167", "order": 1, "source": "UPPER-CONFIDENCE-BOUND (UCB) ACTION SELECTION", "target": "K-ARMED BANDIT PROBLEM"}, {"weight": 6.0, "description": "Monte Carlo Prediction is a technique that can help in the exploration-exploitation trade-offs by using observed experiences to estimate the value of actions.", "source_id": "chunk-0d989122d8c7d74335a0147cfedc9167", "order": 1, "source": "MONTE CARLO PREDICTION", "target": "EXPLORATION-EXPLOITATION TRADE-OFFS"}, {"weight": 7.0, "description": "Model-based Reinforcement Learning relies heavily on the concept of MDPs to simulate and plan decision-making processes.", "source_id": "chunk-0d989122d8c7d74335a0147cfedc9167", "order": 1, "source": "MARKOV DECISION PROCESS (MDP)", "target": "MODEL-BASED REINFORCEMENT LEARNING"}, {"weight": 7.0, "description": "Temporal Difference Learning is a cornerstone of Model-free Reinforcement Learning, leveraging real-time computation of value functions without using a model of the environment.", "source_id": "chunk-0d989122d8c7d74335a0147cfedc9167", "order": 1, "source": "MODEL-FREE REINFORCEMENT LEARNING", "target": "TEMPORAL DIFFERENCE LEARNING"}]}